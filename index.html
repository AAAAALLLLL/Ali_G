install.packages("caret")
library(caret)
training<-read.csv("E:\\pml-training.csv")        loading training data set 
testing<-read.csv("E:\\pml-testing.csv")          loading testing data set
View(training)          
set.seed(1846)                                    setting seed for not randomizing in results
ncol(training)
nearzero <- nearZeroVar(training, saveMetrics = TRUE)        detecting N/A variables
training <- training[,!nearzero$nzv]                         omitting N/A variables from training set
ncol(training)                                               
rvar<-sapply(colnames(training),function(x)if(sum(is.na(training[,x]))>0.5*nrow(training)){return(TRUE)}else{return(FALSE)})      applying a function for detecting variables with more than 50 % N/A varaibles
training<-training[,!rvar]              removing variables with more than N/A values from training set
View(training)
training<-training[,-c(1:6)]             first 6 columns of training set is not useful for prediction so they can be deleted 
ncol(training)
c<-findCorrelation(cor(training[,-53]),cutoff = 0.85)           for preprocesss maybe pca can be useful so considering the corr between variables is necessary to be checked
names(training[c])                                              showing the name of the variables with more than 85 % corr
c<-findCorrelation(cor(training[,-53]),cutoff = 0.75)          
names(training[c])                                              showing the name of variables with more than 75% corr
tc<-trainControl(method = "repeatedcv",number = 5,preProcOptions = "pca")       because mostof the variables have good corr with each other pca can be uselful as preprocess. Also repeated cross validation for training set with 5 times repetition applied for reducing overfitting and variance
svmradial<-train(classe~.,data = training,method="svmRadia",trControl=tc)       the first algorithm to use which is considered is radial svm 
confusionMatrix(svmradial)
svmlinear<-train(classe~.,data = training,method="svmLinear",trControl=tc)      then linear svm 
confusionMatrix(svmlinear)       
install.packages("nnet")                                                 installing the package of neural net
library(nnet)    
nn<-train(classe~.,data = training,method="nnet",trControl=tc)           modeling neural net for training data set
confustionMatrix(nn)
tree<-train(classe~.,data = training,method="rpart",trControl=tc)        classification tree then applied 
confusionMatrix(tree)

psvml<-predict(svmlinear,testing)                                      prediction for linear svm
psvmr<-predict(svmradial,testing)                                      prediction for radial svm 
pnn<-predict(nnet,testing)                                             prediction for neural net 
ptree<-predict(tree,testing)                                           prediction for classification tree


psvmr                                               the accuracy of svm radial was 93.4%, then svm linear was 78.35, following by classification tree 50.01% and neural net with 43.98%. So, the highest accuracy with radial svm selected as the best model for prediction.
